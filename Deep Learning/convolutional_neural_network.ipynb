{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "convolutional_neural_network.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "6rmbo2t7ca_z"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Per evitare l'overfitting è necessario fare del preprocessing alle immagini (detto image augmentation). Vengono applicate trasformazioni (shift, zoom, rotazioni) per modificare le immagini e renderle più varie.\n",
        "\n",
        "target_size=dimensione dell'immagine dopo il resize\n",
        "class_mode=il tipo di output aspettato, in questo caso binario essendo solo una classificazione 0 e 1."
      ],
      "metadata": {
        "id": "2FUWHGlNnWIK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "train_set = train_datagen.flow_from_directory(\n",
        "    'dataset/training_set',\n",
        "    target_size=(64,64),\n",
        "    batch_size=32,\n",
        "    class_mode=\"binary\")"
      ],
      "metadata": {
        "id": "Gl95pYtenLSJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Non viene applicata alcuna trasformazione al test set, solo la standardizzazione."
      ],
      "metadata": {
        "id": "gsS19vVxqO37"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "test_set = train_datagen.flow_from_directory(\n",
        "    'dataset/test_set',\n",
        "    target_size=(64,64),\n",
        "    batch_size=32,\n",
        "    class_mode=\"binary\")"
      ],
      "metadata": {
        "id": "FI6j5U8sqE2z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "kernel_size = dimensione della matrice del filtro\n",
        "\n",
        "filters = quanti filtri usare nella convoluzione. Ogni immagine sarà filtrata con n filtri\n",
        "\n",
        "input_shate = nel caso di immagini, il primo layer deve specificare che tipo di input aspettarsi. In questo caso un immagine a colori 64x64px. Definisce anche l'input layer."
      ],
      "metadata": {
        "id": "FA0ttUhtr8kH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn = tf.keras.models.Sequential()\n",
        "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\", input_shape=(64,64,3))) # input layer"
      ],
      "metadata": {
        "id": "KYQUcW95rTjN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "pool_size = dimensione della matrice, cioè l'area in cui viene misurato il massimo\n",
        "\n",
        "strides = di quanto si sposta la matrice dopo aver calcolato il massimo."
      ],
      "metadata": {
        "id": "rBUPkr9Xsu6j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))"
      ],
      "metadata": {
        "id": "HVA3hDy9sjIr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Viene aggiunto un secondo layer con convoluzione e pooling"
      ],
      "metadata": {
        "id": "E9HEX3GZtYRb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\"))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))"
      ],
      "metadata": {
        "id": "2B4Tw2VFtRM0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Le matrici risultati vengono appiattite e diventano un singolo vettore"
      ],
      "metadata": {
        "id": "rWj38lD9thia"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Flatten())"
      ],
      "metadata": {
        "id": "X-_YxRnOtXj1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Essendo un network per computer vision più complesso di un semplice ANN, vengono usati più neuroni."
      ],
      "metadata": {
        "id": "vcmhQlcWt8E0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))"
      ],
      "metadata": {
        "id": "2kSzDn2FtuYy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid')) # output layer "
      ],
      "metadata": {
        "id": "txH4pAtYuJhg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "cnn.fit(x=train_set, validation_data=test_set, epochs=25)"
      ],
      "metadata": {
        "id": "SnoYWYIxNPS7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "L'immagine viene caricata in formato PIL, ma il network richiede di avere un array.\n",
        "\n",
        "L'immagine viene quindi trasformata in un array compatibile.\n",
        "Inoltre, il CNN ha come input un batch di immagini, quindi è presente un ulteriore dimensione nel dataset che è appunto il batch di immagini.\n",
        "\n",
        "Viene aggiunta una dimensione all'array con expand_dims. La dimensione viene aggiunta all'inizio perchè è corretto che la prima dimensione rappresenti il numero del batch e le altre dimensioni rappresentino l'immagine al suo interno."
      ],
      "metadata": {
        "id": "Ue_SiNkTPmpj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "\n",
        "test_image = image.load_img(\"dataset/single_prediction/cat_or_dog_1.jpg\", target_size=(64,64))\n",
        "test_image = image.img_to_array(test_image)/255\n",
        "test_image = np.expand_dims(test_image, axis=0)\n",
        "result = cnn.predict(test_image)\n",
        "print(train_set.class_indices)\n",
        "# [batch][prediction] c'è solo un batch con all'interno l'unica immagine testata\n",
        "if result[0][0] > 0.5:\n",
        "  prediction = \"dog\"\n",
        "else:\n",
        "  prediction = \"cat\"\n",
        "\n",
        "print(prediction)"
      ],
      "metadata": {
        "id": "fo4_29SIOLEt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}